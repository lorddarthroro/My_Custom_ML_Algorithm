{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8faf90db-9cac-4d1c-9643-03edc5a300be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset to use\n",
    "from sklearn.datasets import load_diabetes\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "# Create a DataFrame from the dataset\n",
    "data = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "data['target'] = diabetes.target  # Add the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6150eb16-812b-41a4-b38e-3d2057a6cd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 53.85344583676593\n"
     ]
    }
   ],
   "source": [
    "# Example to use as frame of reference for accuracy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Initialize and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the scaled testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a37a9289-2e6e-4c94-ae68-53a7079a5be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "class CustomModel:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "    \n",
    "    def fit(self, X_train, y_train, n):\n",
    "        w = []\n",
    "        # Convert DataFrames to NumPy arrays\n",
    "        X_train_array = X_train.to_numpy()\n",
    "        y_train_array = y_train.to_numpy().transpose()\n",
    "\n",
    "        # To initialize w: For each column of X, I want to find the average. \n",
    "        # Then, find the average for y (1 dimmensional). For each x, divide \n",
    "        # y by x, and make that a matrix. \n",
    "        \n",
    "        feature_means = np.mean(X_train_array, axis=0)\n",
    "        y_mean = np.mean(y_train_array)\n",
    "        \n",
    "        # Calculate the ratio of each feature to the mean of y\n",
    "        w = np.divide(feature_means, y_mean)\n",
    "\n",
    "        # TODO: Add code to optimize w    \n",
    "  \n",
    "        # for _ in range(n):\n",
    "        #     y_pred = np.dot(X_train_array, w)\n",
    "        #     error = y_pred - y_train_array\n",
    "            \n",
    "        #     # Update weights\n",
    "        #     gradient = .001 * np.dot(X_train_array.T, error) / len(X_train_array) \n",
    "        #     w -= gradient  # Update weights using gradient descent\n",
    "        #     error = np.dot(X_train_array, w) - y_train_array\n",
    "        #     # Update weights\n",
    "        #     w -= error\n",
    "        self.model = w\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        # Convert DataFrame to NumPy array\n",
    "        X_test_array = X_test.to_numpy()\n",
    "        \n",
    "        # Perform prediction: X_test * w\n",
    "        y_pred = np.dot(X_test_array, self.model)\n",
    "        \n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "82ee4e07-30a4-4482-aa05-b98e62859fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call model and train. Obtain accuracy\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Assuming you want to split into 80% training and 20% testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "custom_model = CustomModel()\n",
    "custom_model.fit(X_train, y_train, n=100000)\n",
    "y_pred = custom_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8b0ddfef-bf44-4c51-b307-21098f3f194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ddd77b99-3cf8-416d-ab5e-035420fea88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162.9373628985285"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe13051d-e898-434e-97b5-2ac7117f23cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
